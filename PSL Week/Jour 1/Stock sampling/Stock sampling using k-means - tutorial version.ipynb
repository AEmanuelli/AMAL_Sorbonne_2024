{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --upgrade threadpoolctl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphical parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (15, 6) # (w, h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set path for dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = # insert path to data here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dataset into pandas dataframe and sort by stock + date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(path + \"stocks.csv\")\n",
    "df = df.sort_values(by=['PERMNO', \"date\"])\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of each firm's activity sector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sectors = # 1 row per stock with columns |TICKER|sector_1dgt|\n",
    "sectors.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rearrange data to get dates in first column and one stock per column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = # insert code here\n",
    "print(df1.shape)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = # first 134 observations of stocks \n",
    "test = # next observations until end of dataframe\n",
    "train_dates = train.index.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute each stock's cumulated return for graphical display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cum_ret = train.cumsum()\n",
    "cum_ret.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cum_ret.plot(legend=False) # legend=False to disable legend display due to the high number of stocks (300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rearrange data with stocks in rows and returns in columns to treat returns as stock features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pivot = # insert code here\n",
    "print(data_pivot.shape)\n",
    "data_pivot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute 8 clusters based on return behavior on the train period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = # intantiate KMeans with 8 clusters, random_state=0. Then train model (fit method)\n",
    "clusters = pd.DataFrame(kmeans.cluster_centers_)\n",
    "clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <u>Question</u>: give the interpretation of each row in the *clusters* table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transpose table so as to get centroid returns in colums and plot cumulated returns by cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clust_data = # transposed \"clusters\" table\n",
    "nb_clusters = # retrieve number of clusters\n",
    "New_labels=[\"Cluster \" + str(x) for x in range(nb_clusters)] # Create cluster names\n",
    "clust_data.columns = New_labels\n",
    "clust_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cum_ret = clust_data.cumsum() # compute cumulated returns\n",
    "dates = data_pivot.columns # retrieve dates. Objective : create plot with dates on horizontal axis\n",
    "cum_ret[\"date\"] = dates # add date column in cum_ret\n",
    "cum_ret = cum_ret.set_index([\"date\"]) # set \"date\" column as the index (will be considered as x values in plot)\n",
    "cum_ret.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve the cluster a firm belongs to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clust = # use kmeans object predict method\n",
    "clust"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count the number of firms in each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_temp = data_pivot.copy() # we want to leave data_pivot untouched\n",
    "data_temp[\"cluster\"] = # assign to each firm the cluster it belongs to based on 'clust' array\n",
    "# count number of firms per cluster using 'groupby'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do clusters match activity sector of firms?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_temp2 = pd.DataFrame(data_temp[\"cluster\"]).reset_index() # keep cluster values only\n",
    "match_sector = # merge data_temp2 with sectors table\n",
    "# report nobs, mean, min, max and std of sector for each cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <u>Question</u>: do clusters match the activity sector of firms?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Returns of equally-weighted portfolio from each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PF = # compute time series of returns of each cluster portfolio\n",
    "PF_cumret = # compute cumulated returns of each portfolio\n",
    "PF_cumret.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <u>Question</u>: compare with centroid cumulated returns graph. Why do we get the same graphs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many clusters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = []\n",
    "for i in np.arange(1, 50):\n",
    "    kmeans = # train model with i clusters. Set random_state to 0 to get comparable results\n",
    "    #append computed error to error list\n",
    "errors = pd.DataFrame(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(1, 50), error, \"b-\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elbow rule: To determine the optimal number of clusters, we have to select the value of k at the “elbow” i.e. the point after which the inertia starts decreasing in a linear fashion. No clear k here... 10 seems to be a reasonable choice however."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_optim = KMeans(n_clusters=10, random_state=0).fit(data_pivot)\n",
    "clusters = pd.DataFrame(kmeans_optim.cluster_centers_)\n",
    "\n",
    "clust_data = clusters.T\n",
    "nb_clusters = clusters.shape[0] # retrieve number of clusters\n",
    "New_labels=[\"Cluster \" + str(x) for x in range(nb_clusters)] # Build cluster names\n",
    "clust_data.columns = New_labels\n",
    "clust_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cum_ret = clust_data.cumsum() # compute cumulated returns\n",
    "dates = data_pivot.columns # retrieve dates. Objective : create plot with dates on horizontal axis\n",
    "cum_ret[\"date\"] = dates # create date column in cum_ret\n",
    "cum_ret = cum_ret.set_index([\"date\"]) # set \"date\" column as the index (will be considered as x values in plots)\n",
    "cum_ret.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of stocks in each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_temp = data_pivot.copy() # we want to leave data_pivot untouched\n",
    "data_temp[\"cluster\"] = kmeans_optim.predict(data_pivot)\n",
    "nb_stocks = data_temp.groupby(\"cluster\")[\"cluster\"].count()\n",
    "nb_stocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the most representative stock within each cluster, i.e. the one closest to the cluster centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "closest, _ = pairwise_distances_argmin_min(kmeans_optim.cluster_centers_, data_pivot)\n",
    "closest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_fits = # for each cluster, select the stock that is closest to the cluster centroid\n",
    "cum_best_fits = # compute cumulated returns of each selected stock\n",
    "cum_best_fits.head()\n",
    "cum_best_fits.round(decimals=3).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <u>Question</u>: there are 2 clusters with one stock only. Which stocks are in thse clusters? Does it make sense that these stocks are alone in their cluster?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot of selected stock returns and centroid returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(5, 2)\n",
    "fig.tight_layout(pad=3.0)\n",
    "cum_best_fits_cols = cum_best_fits.columns\n",
    "cum_ret_cols = cum_ret.columns\n",
    "for i in range(len(cum_best_fits_cols)):\n",
    "    row = int(i/2)\n",
    "    j = i%2\n",
    "    cur_col_best_fits = cum_best_fits_cols[i]\n",
    "    cur_col_cum_ret = cum_ret_cols[i]\n",
    "    s = pd.concat([cum_best_fits[cur_col_best_fits],\n",
    "                   cum_ret[cur_col_cum_ret]], axis=1).reset_index(drop=True) # reset_index + drop otherwise dates\n",
    "                                                                             # are reported on x axis and are unreadable\n",
    "    axs[row,j].plot(s)\n",
    "    axs[row,j].title.set_text(\"Nb stocks = {}\".format(nb_stocks[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot of selected stock returns against centroid returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_fits2 = best_fits.T\n",
    "best_fits2 = best_fits2.reset_index(drop=True)\n",
    "\n",
    "fig, axs = plt.subplots(5, 2)\n",
    "fig.tight_layout(pad=3.0)\n",
    "best_fits2_cols = best_fits2.columns\n",
    "ret_cols = clust_data.columns\n",
    "for i in range(len(best_fits2_cols)):\n",
    "    row = int(i/2)\n",
    "    j = i%2\n",
    "    cur_col_best_fits2 = best_fits2_cols[i]\n",
    "    cur_col_ret = ret_cols[i]\n",
    "    s1 = best_fits2[cur_col_best_fits2]\n",
    "    s2 = clust_data[cur_col_ret]\n",
    "    axs[row,j].plot(s1,s2, \"ro\", ms=1)\n",
    "    axs[row,j].axline([0, 0], [1, 1])\n",
    "    axs[row,j].title.set_text(\"Nb stocks = {}\".format(nb_stocks[i]))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can we replicate the whole portfolio (300 stocks) with the 10 representative stocks only?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance on train set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation bewteen whole portfolio returns and 10-stock portfolio returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret_PF_all = # compute the time series of returns of the 300-stock equally-weighted porfolio on train set\n",
    "ret_PF_repr_stocks =  # compute the time series of returns of the 10-stock equally-weighted porfolio on train set\n",
    "# compute the correlation in returns of the two portfolios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <u>Question</u>: what is the quality of the replication of the 300-stock portfolio by the 10-stock portfolio on the train set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot of returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret_all_train = pd.DataFrame(ret_PF_all)\n",
    "ret_repr_train = pd.DataFrame(ret_PF_repr_stocks)\n",
    "ret_train = pd.concat([ret_all_train, ret_repr_train], axis=1)\n",
    "ret_train.columns = ['all', 'selected']\n",
    "ret_train.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance on test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret_PF_all = # compute the time series of returns of the 300-stock equally-weighted porfolio on train set\n",
    "best_fits = # retrieve the returns of the 10 stocks on the test set\n",
    "ret_PF_repr_stocks = # compute the time series of returns of the 10-stock equally-weighted porfolio on test set\n",
    "# compute the correlation in returns of the two portfolios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <u>Question</u>: what is the quality of the replication of the 300-stock portfolio by the 10-stock portfolio on the test set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot of returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret_all_test = pd.DataFrame(ret_PF_all)\n",
    "ret_repr_test = pd.DataFrame(ret_PF_repr_stocks)\n",
    "ret_test = pd.concat([ret_all_test, ret_repr_test], axis=1)\n",
    "ret_test.columns = ['all', 'selected']\n",
    "ret_test.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
